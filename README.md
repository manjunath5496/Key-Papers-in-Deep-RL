<h2>Model-Free RL: </h2>

<p> <strong>Deep Q-Learning </strong> </p>
<hr>
<ul>
  
 <li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(1).pdf" style="text-decoration:none;">Playing Atari with Deep Reinforcement Learning</a></b></li>
  
<li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(2).pdf" style="text-decoration:none;">Deep Recurrent Q-Learning for Partially Observable MDPs</a></b></li>

<li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(3).pdf" style="text-decoration:none;"> Dueling Network Architectures for Deep Reinforcement Learning</a></b></li>                         
  <li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(4).pdf" style="text-decoration:none;">Deep Reinforcement Learning with Double Q-learning</a></b></li>  
<li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(5).pdf" style="text-decoration:none;">Prioritized Experience Replay</a></b></li>  
 <li><b><a target="_blank" href="https://github.com/manjunath5496/Key-Papers-in-Deep-RL/blob/master/plk(6).pdf" style="text-decoration:none;">Rainbow: Combining Improvements in Deep Reinforcement Learning</a></b></li>    

</ul>
